{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba \n",
    "\n",
    "from keras.layers import Dense, Input, Flatten,Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fneg = open('neg.txt','r',encoding='gb18030')\n",
    "fpos = open('pos.txt','r',encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = []\n",
    "pos = []\n",
    "for line in fneg:\n",
    "    neg.append(line)\n",
    "for line in fpos:\n",
    "    pos.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(neg)\n",
    "pos_df = pd.DataFrame(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并语料\n",
    "\n",
    "pn = pd.concat([neg_df, pos_df], ignore_index=True)\n",
    "neg_len = len(neg_df)\n",
    "pos_len = len(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0728 17:47:16.336415 17004 __init__.py:111] Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Andy\\AppData\\Local\\Temp\\jieba.cache\n",
      "I0728 17:47:16.342421 17004 __init__.py:131] Loading model from cache C:\\Users\\Andy\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.955 seconds.\n",
      "I0728 17:47:19.296510 17004 __init__.py:163] Loading model cost 2.955 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "I0728 17:47:19.302014 17004 __init__.py:164] Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#定义分词函数\n",
    "\n",
    "cw = lambda x: list(jieba.cut(x))\n",
    "pn['words'] = pn[0].apply(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将一行最大单词数设为1000\n",
    "max_document_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join(x) for x in pn['words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实例化分词器\n",
    "tokenizer = Tokenizer(num_words=30000)\n",
    "#建立词典\n",
    "tokenizer.fit_on_texts(texts)\n",
    "#将词频和序号对应\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "#将序列设置为1000的长度，超过1000的部分舍弃，不足的补0 补0的位置和CNN不同\n",
    "sequences = pad_sequences(sequences, maxlen=1000)\n",
    "#sequences = np.array(sequences)\n",
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#词对应编号的词典\n",
    "\n",
    "dict_text = tokenizer.word_index\n",
    "dict_text['天']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里的x是句子中每个分词对应的word_index的列表\n",
    "\n",
    "#定义标签\n",
    "positive_labels = [[0, 1] for _ in range(pos_len)]\n",
    "negative_labels = [[1, 0] for _ in range(neg_len)]\n",
    "y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "#打乱数据\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = sequences[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]\n",
    "\n",
    "#数据集切分\n",
    "test_sample_index = -1 * int(0.15 * float(len(y)))\n",
    "x_train, x_test = x_shuffled[:test_sample_index], x_shuffled[test_sample_index:]\n",
    "y_train, y_test = y_shuffled[:test_sample_index], y_shuffled[test_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.recurrent import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型输入\n",
    "sequence_input = Input(shape=(1000,))\n",
    "#Embedding层，30000表示30000个词，每个词对应向量128维，序列长度1000\n",
    "embedding_layer = Embedding(\n",
    "    30000,  #生成一个30000*128的矩阵\n",
    "    128, \n",
    "    input_length=1000\n",
    ")\n",
    "embedding_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "#方法一 LSTM输出为(batch,10)\n",
    "lstm1 = LSTM(10, dropout=0.2, recurrent_dropout=0.2)(embedding_sequences) #10代表10个block\n",
    "lstm1 = Dense(16, activation='relu')(lstm1)\n",
    "lstm1 = Dropout(0.5)(lstm1)\n",
    "\n",
    "#方法二 LSTM输出为（batch,1000,10)\n",
    "lstm2 = LSTM(10,return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(embedding_sequences)\n",
    "lstm2 = Flatten()(lstm2)\n",
    "lstm2 = Dense(16, activation='relu')(lstm2)\n",
    "lstm2 = Dropout(0.5)(lstm2)\n",
    "\n",
    "\n",
    "\n",
    "##输出层\n",
    "\n",
    "preds = Dense(2, activation='softmax')(lstm2)\n",
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编译和训练\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy',\n",
    "    #loss = 'mse',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8500/8500 [==============================] - 442s 52ms/step - loss: 0.4505 - acc: 0.7735\n",
      "Epoch 2/10\n",
      "8500/8500 [==============================] - 386s 45ms/step - loss: 0.2003 - acc: 0.9314\n",
      "Epoch 3/10\n",
      "8500/8500 [==============================] - 350s 41ms/step - loss: 0.1072 - acc: 0.9679\n",
      "Epoch 4/10\n",
      "8500/8500 [==============================] - 396s 47ms/step - loss: 0.0736 - acc: 0.9788\n",
      "Epoch 5/10\n",
      "8500/8500 [==============================] - 393s 46ms/step - loss: 0.0516 - acc: 0.9826\n",
      "Epoch 6/10\n",
      "8500/8500 [==============================] - 398s 47ms/step - loss: 0.0339 - acc: 0.9887\n",
      "Epoch 7/10\n",
      "8500/8500 [==============================] - 431s 51ms/step - loss: 0.0421 - acc: 0.9880\n",
      "Epoch 8/10\n",
      "8500/8500 [==============================] - 455s 54ms/step - loss: 0.0287 - acc: 0.9902\n",
      "Epoch 9/10\n",
      "8500/8500 [==============================] - 447s 53ms/step - loss: 0.0168 - acc: 0.9955\n",
      "Epoch 10/10\n",
      "8500/8500 [==============================] - 373s 44ms/step - loss: 0.0160 - acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa02f06fb38>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练,60000张图片训练一次叫做一个epoch\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500/8500 [==============================] - 60s 7ms/step\n",
      "Loss: 0.010887666234143955\n",
      "Accuracy: 0.9970588235294118\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
